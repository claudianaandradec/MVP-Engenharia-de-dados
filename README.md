# MVP-Engenharia-de-dados
MVP - Engenharia de dados

# 1- OBJETIVO

Este MVP tem como objetivo construir um pipeline de dados na nuvem para analisar informa√ß√µes sobre livros, usu√°rios e avalia√ß√µes, utilizando tecnologias em nuvem com Databricks e seu Delta Lake. O pipeline envolver√° as etapas de busca, coleta, modelagem, carga e an√°lise dos dados, com o prop√≥sito de fornecer insights sobre padr√µes de leitura, comportamento dos usu√°rios e caracter√≠sticas que influenciam a avalia√ß√£o de livros ‚Äî al√©m de estabelecer a base para um sistema simples de recomenda√ß√£o.

O problema central que este MVP busca resolver √© a aus√™ncia de uma vis√£o consolidada e acess√≠vel dos dados de avalia√ß√µes e caracter√≠sticas dos livros, que permita identificar tend√™ncias, prefer√™ncias dos usu√°rios e padr√µes relevantes para o consumo de conte√∫do liter√°rio. Para isso, ser√£o respondidas as seguintes perguntas:

 Sobre livros e avalia√ß√µes
   
1. Quais s√£o os livros mais bem avaliados pelos usu√°rios?
2. Qual √© a m√©dia de avalia√ß√£o por g√™nero liter√°rio?
3. Quais livros possuem maior volume de avalia√ß√µes ao longo do tempo?
4. H√° livros com avalia√ß√µes baixas, mas muito populares?

Sobre comportamento dos usu√°rios
   
5. Quais usu√°rios s√£o mais ativos na plataforma (maior n√∫mero de avalia√ß√µes)?
6. Existe rela√ß√£o entre idade e tipo de livro avaliado?
7. H√° diferen√ßas de avalia√ß√£o entre g√™neros masculino/feminino?
8. Usu√°rios de determinadas faixas et√°rias preferem determinados g√™neros?

Sobre padr√µes no cat√°logo

9. Quais editoras possuem melhor m√©dia de avalia√ß√£o?
10. Existe concentra√ß√£o de livros mal avaliados em determinadas editoras ou autores?

Sobre recomenda√ß√£o

11. Quais s√£o os livros mais recomendados para novos usu√°rios (modelo baseado em popularidade)?
12. √â poss√≠vel sugerir livros semelhantes com base no hist√≥rico de avalia√ß√µes (modelo item-item)?
13. Quais recomenda√ß√µes diferem entre faixas et√°rias e g√™neros?

Sobre qualidade dos dados

14. Existem inconsist√™ncias nas avalia√ß√µes (valores nulos, fora do intervalo ou duplicados)?
15. Existem livros ou usu√°rios com informa√ß√µes incompletas no dataset?

üéØ **Objetivo final**

Ao final do projeto, espera-se entregar:
Um pipeline de dados completo (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold)
Um modelo de dados estruturado em formato estrela (DW)
Um cat√°logo dos dados documentado
An√°lises explorat√≥rias e de qualidade dos dados
Visualiza√ß√µes e respostas √†s perguntas definidas
Um sistema simples de recomenda√ß√£o baseado nas avalia√ß√µes
Com isso, o MVP pretende demonstrar como pipelines em nuvem podem apoiar experi√™ncias de recomenda√ß√£o e permitir uma an√°lise eficiente de grandes volumes de dados liter√°rios.

# 2- COLETA DE DADOS

## Fonte dos Dados e Processo de Coleta

Os dados utilizados neste projeto foram obtidos de fontes abertas e p√∫blicas, eliminando riscos relacionados √† confidencialidade das informa√ß√µes. A base principal re√∫ne metadados de livros, avalia√ß√µes e prefer√™ncias de usu√°rios, compondo o insumo necess√°rio para o desenvolvimento de um sistema de recomenda√ß√£o. Foram coletados dados entre os anos de 1998 e 2024, conforme a disponibilidade de cada fonte.

### Tabela Fato ‚Äì Intera√ß√µes Usu√°rio‚ÄìLivro

A tabela fato do projeto, denominada fato_interacoes_usuarios_gold, foi constru√≠da a partir de registros de intera√ß√µes (ratings, reviews e marca√ß√µes) coletados do portal Goodreads por meio de datasets disponibilizados publicamente no Kaggle.

üîó Fonte principal:
Goodreads Books Dataset ‚Äì Kaggle (https://www.kaggle.com/datasets/zygmunt/goodbooks-10k)
(arquivo contendo livros, avalia√ß√µes, notas e intera√ß√µes de usu√°rios)

Esse dataset foi escolhido por possuir volume significativo, metadata completa e padroniza√ß√£o adequada para an√°lises avan√ßadas de recomenda√ß√£o.

Os arquivos foram baixados manualmente, no formato CSV, e posteriormente enviados para o reposit√≥rio GitHub do projeto. O pipeline foi configurado para realizar o ingest dos dados diretamente via API do GitHub, permitindo atualiza√ß√£o simplificada e versionada.

### Tabelas Dimens√£o

As tabelas dimens√£o foram obtidas de diferentes fontes complementares, conforme detalhado abaixo.

üìò **Dimens√£o Livros (dim_livros_gold)**

Para enriquecer as informa√ß√µes dos livros, foi utilizada a base do dataset:

üîó Fonte:
Goodreads Books Dataset (books.csv)
Cont√©m: t√≠tulo, autores, ISBN, idioma, n√∫mero de p√°ginas, ano de publica√ß√£o, m√©dia de avalia√ß√£o e descri√ß√£o.

Esse conjunto foi selecionado por fornecer metadados essenciais para a qualidade das recomenda√ß√µes baseadas em conte√∫do (content-based filtering).

üßë‚Äçüíª **Dimens√£o Usu√°rios (dim_usuarios_gold)**

Como as bases p√∫blicas de recomenda√ß√£o n√£o incluem dados pessoais, somente IDs an√¥nimos, utilizamos os identificadores do pr√≥prio dataset:

üîó Fonte:
Goodreads Interactions Dataset (ratings.csv / interactions.csv)
Cont√©m: user_id, book_id, rating e timestamp.

Por motivos de privacidade, nenhuma informa√ß√£o sens√≠vel √© inclu√≠da, mantendo o dataset totalmente anonimizado e compat√≠vel com LGPD.

üè∑Ô∏è **Dimens√£o G√™neros Liter√°rios (dim_generos_gold)**

As informa√ß√µes de g√™neros foram extra√≠das de forma complementar a partir da API p√∫blica do Google Books, utilizada apenas para enriquecer metadata faltante em alguns livros.

üîó Fonte:
Google Books API ‚Äì consulta automatizada para g√™neros e categorias liter√°rias.

Os dados foram coletados em formato JSON e transformados em CSV para carga no pipeline.

### Outras Tabelas Dimens√£o Criadas Manualmente

Algumas tabelas possu√≠am poucas linhas e foram facilmente criadas manualmente em CSV, com separa√ß√£o por ‚Äú;‚Äù, utilizando um editor de texto. Essas tabelas incluem classifica√ß√µes auxiliares utilizadas no modelo de recomenda√ß√£o:

Popularidade (popularidade_gold)
Faixa de Ano de Publica√ß√£o (faixa_ano_gold)
Categorias Simplificadas (categoria_simplificada_gold)

Essas tabelas foram constru√≠das com base na estrutura do pr√≥prio dataset e projetadas para auxiliar no enriquecimento do processo anal√≠tico.

# 3- MODELAGEM E CAT√ÅLOGO DE DADOS

Para estruturar e organizar os dados de forma eficiente, foi adotado o Esquema Estrela, amplamente utilizado em solu√ß√µes de Data Warehousing, Business Intelligence e sistemas de recomenda√ß√£o baseados em an√°lises anal√≠ticas.

## Estrutura do Esquema Estrela

O esquema estrela do projeto foi constru√≠do com uma tabela fato principal contendo as intera√ß√µes entre usu√°rios e livros, acompanhada de cinco tabelas dimens√£o, que consolidam e organizam os metadados necess√°rios para alimentar o motor de recomenda√ß√µes.

A arquitetura ficou estruturada da seguinte forma:

üìò **Tabela Fato: fato_interacoes_usuarios_gold**

A tabela fato cont√©m os registros de comportamento dos usu√°rios, sendo o n√∫cleo central do modelo.
Cada linha representa uma intera√ß√£o √∫nica, como:

* avalia√ß√£o (rating)
* marca√ß√£o de leitura (read / want-to-read)
* review textual
* data e hora da intera√ß√£o

Esses dados s√£o a base para algoritmos de recomenda√ß√£o como:
‚úî Filtragem Colaborativa
‚úî Content-Based Filtering
‚úî Modelos H√≠bridos

üìä **Tabelas Dimens√£o**

Foram criadas tabelas auxiliares para armazenar atributos descritivos, garantindo enriquecimento e consist√™ncia das an√°lises por meio de joins.

As dimens√µes utilizadas foram:

* dim_livros_gold ‚Äì informa√ß√µes dos livros (t√≠tulo, autor, ISBN, idioma, ano)
* dim_usuarios_gold ‚Äì identificador do usu√°rio (anonimizado)
* dim_generos_gold ‚Äì g√™neros liter√°rios e categorias tem√°ticas
* dim_popularidade_gold ‚Äì classifica√ß√£o de popularidade baseada em m√©dia de notas e volume de reviews
* dim_ano_publicacao_gold ‚Äì agrupamentos de ano para an√°lises temporais

Essas dimens√µes permitem que cada intera√ß√£o seja contextualizada, criando um ambiente anal√≠tico robusto para recomenda√ß√µes personalizadas.

## Cat√°logo de Dados
### Tabela fato_interacoes_usuarios_gold

A tabela fato foi constru√≠da a partir da base original do Goodreads, que continha dezenas de campos sobre avalia√ß√µes, metadados do livro e comportamento do usu√°rio.

Durante o processo de ETL, v√°rios campos redundantes ou irrelevantes foram removidos, resultando em uma estrutura mais enxuta, organizada e otimizada para an√°lises de recomenda√ß√£o.

A estrutura final da tabela fato cont√©m os seguintes campos:

### Tabelas Dimens√£o

| Campo            | Descri√ß√£o                                    |
| ---------------- | -------------------------------------------- |
| interaction_id   | Identificador √∫nico da intera√ß√£o             |
| user_id          | Identificador anonimizado do usu√°rio         |
| book_id          | Identificador √∫nico do livro                 |
| rating           | Nota atribu√≠da pelo usu√°rio                  |
| review_text      | Texto do coment√°rio (quando dispon√≠vel)      |
| interaction_type | Tipo de intera√ß√£o (rating, review, marca√ß√£o) |
| timestamp        | Data/hora da intera√ß√£o                       |
| source           | Origem do dado (Goodreads / Kaggle / API)    |

Resumo da estrutura das dimens√µes inclu√≠das no modelo:
### dim_livros_gold

| Campo            | Descri√ß√£o                 |
| ---------------- | ------------------------- |
| book_id          | Chave prim√°ria do livro   |
| title            | T√≠tulo                    |
| authors          | Autor(es)                 |
| isbn             | Identifica√ß√£o ISBN        |
| language         | Idioma                    |
| pages            | N√∫mero de p√°ginas         |
| publication_year | Ano de publica√ß√£o         |
| avg_rating       | M√©dia geral de avalia√ß√µes |

### dim_usuarios_gold

| Campo         | Descri√ß√£o                  |
| ------------- | -------------------------- |
| user_id       | Identificador anonimizado  |
| total_reviews | Volume de reviews escritos |
| total_ratings | Total de avalia√ß√µes        |

### dim_generos_gold
| Campo      | Descri√ß√£o                |
| ---------- | ------------------------ |
| genre_id   | Chave prim√°ria           |
| genre_name | Nome do g√™nero liter√°rio |

### dim_popularidade_gold
| Campo            | Descri√ß√£o                        |
| ---------------- | -------------------------------- |
| popularity_id    | Chave prim√°ria                   |
| popularity_level | Baixa / M√©dia / Alta             |
| rule             | Regra utilizada na classifica√ß√£o |

### dim_ano_publicacao_gold
| Campo       | Descri√ß√£o                       |
| ----------- | ------------------------------- |
| year_group  | Faixa de ano (ex.: "1990‚Äì1999") |
| description | Categoria anal√≠tica             |

# Diagrama Entidade Relacionamento

![image alt](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/a3d93143e37b0f6e5e48777a1158f837517be1c7/Diagrama%20ER.jpg)

# 4- Carga (ETL) ‚Äì Pipeline no Databricks

Nesta etapa ser√° constru√≠do o pipeline de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) respons√°vel por ingerir, limpar, padronizar e disponibilizar os dados no Delta Lake.

Utilizaremos a arquitetura Medallion, dividindo o processamento em tr√™s camadas:

ü•â Bronze ‚Äì dados brutos

ü•à Silver ‚Äì dados tratados e padronizados

ü•á Gold ‚Äì dados modelados no Esquema Estrela

**Esta se√ß√£o est√° dentro do notebook**
[Notebook](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/aba50bf3bc49f1f5e9b5217acb694b65820e63c4/Analise_Exploratoria_engenharia_de_dados.ipynb)

# 5- AN√ÅLISE

**Esta se√ß√£o est√° dentro do notebook**
[Notebook](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/ca070b364c734562e9e73238c8c3ca7a5a442dec/Analise_indicadores.ipynb)

![image alt](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/cd23fed059627db2ca84ce036aa7dcb8639458d2/visualization_top_10.png) 

![image alt](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/2356723567e31616a755b8a16a2c3329c387ed6b/visualization_Generos.png)

## An√°lise da qualidade dos dados 

Durante a execu√ß√£o do pipeline de dados (arquitetura Medallion: Bronze ‚Üí Silver ‚Üí Gold), os dados passaram por diversas verifica√ß√µes de integridade, tipagem e consist√™ncia. O objetivo foi garantir que a camada final (Gold) estivesse apta para gerar insights confi√°veis sobre o comportamento de leitura.
Nesta se√ß√£o, foi detalhada a qualidade dos atributos, os problemas encontrados nos arquivos brutos e as solu√ß√µes t√©cnicas aplicadas.

**1. Sele√ß√£o e Limpeza de Atributos**

O dataset original (books.csv) possu√≠a diversas colunas irrelevantes para o objetivo anal√≠tico deste MVP, como URLs de capas de livros (image_url, small_image_url) e m√∫ltiplos contadores internos redundantes.
Para otimizar o armazenamento e a performance das consultas no Data Warehouse, foi realizada a remo√ß√£o dessas colunas durante a transi√ß√£o para a camada Silver, mantendo apenas os metadados essenciais (t√≠tulo, autor, ano, ISBN e identificadores).

**2. Inconsist√™ncias de Tipagem e "Dados Sujos"**

Um dos problemas cr√≠ticos identificados foi a presen√ßa de "sujeira" (dirty data) em colunas num√©ricas.
Problema: Na coluna average_rating, que deveria conter apenas valores decimais (double), foram encontrados registros contendo texto (ex: o valor "eng", que pertence √† coluna de idioma, foi deslocado para a coluna de nota em algumas linhas corrompidas).
Solu√ß√£o: foi utilizada a fun√ß√£o try_cast do Spark. Diferente de uma convers√£o comum que falharia o pipeline, essa abordagem converteu os valores inv√°lidos para NULL. Em seguida, aplicamos um filtro (isNotNull) na chave prim√°ria para descartar essas linhas corrompidas, garantindo que apenas livros com dados estruturados chegassem √† camada Gold.

**3. Tratamento de Identificadores (Chaves Prim√°rias)**

Houve uma inconsist√™ncia sem√¢ntica nos identificadores dos livros. O dataset continha dois IDs distintos: um sequencial do pr√≥prio arquivo (book_id) e outro original do site Goodreads (goodreads_book_id).
Problema: A tabela de tags utilizava o ID do site, enquanto a tabela de ratings utilizava o ID sequencial.
Solu√ß√£o: Realizado um mapeamento expl√≠cito e renomea√ß√£o dessas colunas na camada Silver. Isso garantiu a integridade referencial nos Joins da camada Gold, permitindo cruzar corretamente as avalia√ß√µes dos usu√°rios com os g√™neros liter√°rios.

**4. Tratamento de Valores Nulos e Duplicatas**

Duplicatas: Embora raro, o processo de ingest√£o poderia gerar duplicidade de processamento. Foi aplicada a fun√ß√£o .dropDuplicates() baseada nas chaves naturais (ex: um usu√°rio n√£o pode ter duas avalia√ß√µes para o mesmo livro; mantivemos apenas a mais recente ou √∫nica).
Nulos: Campos textuais essenciais, como original_title, passaram por tratamento de limpeza (trim) para remover espa√ßos em branco. Para livros sem hist√≥rico de avalia√ß√µes no dataset, foi preenchido os valores nulos de contagem com 0 (zero) para n√£o prejudicar os c√°lculos de m√©dia.

**5. Qualidade Estat√≠stica para Recomenda√ß√£o**

Notou-se que alguns livros possu√≠am m√©dias de avalia√ß√£o muito altas (5.0), mas com apenas 1 ou 2 votos. Estatisticamente, isso gera um vi√©s de recomenda√ß√£o ("falsos melhores livros").
Solu√ß√£o: Foram criadas regras de neg√≥cio na camada Gold para classificar a popularidade. Nas an√°lises de recomenda√ß√£o, foram aplicados filtros (ex: ratings_count > 100) para garantir que os insights refletissem o consenso da comunidade e n√£o outliers.

# 6- Conclus√£o

Ap√≥s as etapas de limpeza, tipagem robusta (uso de try_cast) e modelagem dimensional, os dados atingiram um n√≠vel de qualidade satisfat√≥rio. As inconsist√™ncias estruturais foram sanadas na camada Silver, permitindo que a camada Gold responda √†s perguntas de neg√≥cio com precis√£o e sem interrup√ß√µes no processamento.

# Atingimento do objetivo
‚úÖ **Respondidas com Sucesso**

Estas perguntas foram respondidas diretamente pelas queries SQL e tabelas criadas no Databricks.  
**Sobre livros:**
Quais s√£o os livros mais bem avaliados? (Sim, query Top 10 por m√©dia).  
Qual √© a m√©dia de avalia√ß√£o por g√™nero liter√°rio? (Sim, via tabela bridge_livros_tags).  
Quais livros possuem maior volume de avalia√ß√µes? (Sim, ordena√ß√£o por contagem).  
H√° livros com avalia√ß√µes baixas, mas muito populares? (Sim, query de "Livros Pol√™micos").

**Sobre comportamento:**  
Quais usu√°rios s√£o mais ativos na plataforma? (Sim, via dim_usuarios).

**Sobre padr√µes (Adaptado):**  
Existe concentra√ß√£o de livros mal avaliados em determinados autores? (Sim, adapta√ß√£o de Editoras para Autores).  
**Sobre recomenda√ß√£o:**  
Quais s√£o os livros mais recomendados para novos usu√°rios? (Sim, query Cold Start/Popularidade).  
√â poss√≠vel sugerir livros semelhantes (item-item)? (Sim, simulado via filtro de G√™neros/Tags).  

**Sobre qualidade:**
Existem inconsist√™ncias? (Sim, detectado o erro "eng" na nota e IDs trocados).  
Informa√ß√µes incompletas? (Sim, tratados nulos na Silver).  

‚ùå **N√£o Respondidas / Escopo Ajustado "Limita√ß√µes do Dataset".**
"Existe rela√ß√£o entre idade e tipo de livro avaliado?"  
"H√° diferen√ßas de avalia√ß√£o entre g√™neros masculino/feminino?"  
"Usu√°rios de determinadas faixas et√°rias preferem determinados g√™neros?"  
"Quais recomenda√ß√µes diferem entre faixas et√°rias e g√™neros?"  
**Motivo:** Privacidade e Anonimiza√ß√£o. O dataset p√∫blico escolhido (Goodbooks-10k/Kaggle) cont√©m apenas o ID do usu√°rio (user_id). Por quest√µes de prote√ß√£o de dados e conformidade com leis de privacidade (como a LGPD/GDPR), plataformas p√∫blicas raramente disponibilizam dados demogr√°ficos (Idade, Sexo, Localiza√ß√£o) de seus usu√°rios.  
"Quais editoras possuem melhor m√©dia de avalia√ß√£o?"    
**Motivo:** Disponibilidade de Metadados. A coluna publisher n√£o apresentava consist√™ncia ou completude suficiente na camada Bronze (muitos nulos ou nomes duplicados como "Penguin" vs "Penguin Books").
Solu√ß√£o: O escopo foi reorientado para analisar Autores, um dado muito mais confi√°vel e preenchido na base.

## CONSIDERA√á√ïES FINAIS E ADER√äNCIA AO ESCOPO
Ao final do desenvolvimento do pipeline de dados e das an√°lises explorat√≥rias, foi poss√≠vel responder √† grande maioria das perguntas de neg√≥cio propostas, fornecendo uma vis√£o clara sobre os livros mais populares, os g√™neros dominantes e o comportamento de engajamento dos usu√°rios (Heavy Users).
Limita√ß√µes e Ajustes de Escopo, contudo, algumas perguntas planejadas inicialmente n√£o puderam ser respondidas devido √† natureza dos dados coletados:
Dados Demogr√°ficos (Idade e G√™nero do Usu√°rio): As an√°lises segmentadas por faixa et√°ria e g√™nero sexual n√£o foram realizadas. O dataset utilizado (Goodbooks-10k), assim como a maioria das fontes abertas de sistemas de recomenda√ß√£o, submete os dados dos usu√°rios a um processo de anonimiza√ß√£o para proteger a privacidade. Portanto, a tabela de usu√°rios restringiu-se a m√©tricas comportamentais (frequ√™ncia de intera√ß√£o) e n√£o demogr√°ficas.
An√°lise de Editoras: Durante a etapa de Data Quality na camada Bronze, identificou-se que a informa√ß√£o sobre "Editoras" possu√≠a baixa confiabilidade (muitos valores nulos ou n√£o padronizados). Optou-se estrategicamente por substituir essa an√°lise pela vis√£o de Autores, garantindo maior precis√£o nos insights sobre a qualidade do cat√°logo.
Conclus√£o
O MVP cumpriu seu objetivo principal: estruturar um Lakehouse funcional no Databricks, com dados tratados e confi√°veis na camada Gold, habilitando tanto an√°lises hist√≥ricas quanto a base para um sistema de recomenda√ß√£o baseado em conte√∫do e popularidade.
