# MVP-Engenharia-de-dados
MVP - Engenharia de dados

# OBJETIVO

Este MVP tem como objetivo construir um pipeline de dados na nuvem para analisar informaÃ§Ãµes sobre livros, usuÃ¡rios e avaliaÃ§Ãµes, utilizando tecnologias em nuvem com Databricks e seu Delta Lake. O pipeline envolverÃ¡ as etapas de busca, coleta, modelagem, carga e anÃ¡lise dos dados, com o propÃ³sito de fornecer insights sobre padrÃµes de leitura, comportamento dos usuÃ¡rios e caracterÃ­sticas que influenciam a avaliaÃ§Ã£o de livros â€” alÃ©m de estabelecer a base para um sistema simples de recomendaÃ§Ã£o.

O problema central que este MVP busca resolver Ã© a ausÃªncia de uma visÃ£o consolidada e acessÃ­vel dos dados de avaliaÃ§Ãµes e caracterÃ­sticas dos livros, que permita identificar tendÃªncias, preferÃªncias dos usuÃ¡rios e padrÃµes relevantes para o consumo de conteÃºdo literÃ¡rio. Para isso, serÃ£o respondidas as seguintes perguntas:

 Sobre livros e avaliaÃ§Ãµes
   
1. Quais sÃ£o os livros mais bem avaliados pelos usuÃ¡rios?
2. Qual Ã© a mÃ©dia de avaliaÃ§Ã£o por gÃªnero literÃ¡rio?
3. Quais livros possuem maior volume de avaliaÃ§Ãµes ao longo do tempo?
4. HÃ¡ livros com avaliaÃ§Ãµes baixas, mas muito populares?

Sobre comportamento dos usuÃ¡rios
   
6. Quais usuÃ¡rios sÃ£o mais ativos na plataforma (maior nÃºmero de avaliaÃ§Ãµes)?
7. Existe relaÃ§Ã£o entre idade e tipo de livro avaliado?
8. HÃ¡ diferenÃ§as de avaliaÃ§Ã£o entre gÃªneros masculino/feminino?
9. UsuÃ¡rios de determinadas faixas etÃ¡rias preferem determinados gÃªneros?

Sobre padrÃµes no catÃ¡logo

11. Quais editoras possuem melhor mÃ©dia de avaliaÃ§Ã£o?
12. Existe concentraÃ§Ã£o de livros mal avaliados em determinadas editoras ou autores?

Sobre recomendaÃ§Ã£o

14. Quais sÃ£o os livros mais recomendados para novos usuÃ¡rios (modelo baseado em popularidade)?
15. Ã‰ possÃ­vel sugerir livros semelhantes com base no histÃ³rico de avaliaÃ§Ãµes (modelo item-item)?
16. Quais recomendaÃ§Ãµes diferem entre faixas etÃ¡rias e gÃªneros?

Sobre qualidade dos dados

14. Existem inconsistÃªncias nas avaliaÃ§Ãµes (valores nulos, fora do intervalo ou duplicados)?
15. Existem livros ou usuÃ¡rios com informaÃ§Ãµes incompletas no dataset?

ğŸ¯ Objetivo final

Ao final do projeto, espera-se entregar:
Um pipeline de dados completo (Raw â†’ Bronze â†’ Silver â†’ Gold)
Um modelo de dados estruturado em formato estrela (DW)
Um catÃ¡logo dos dados documentado
AnÃ¡lises exploratÃ³rias e de qualidade dos dados
VisualizaÃ§Ãµes e respostas Ã s perguntas definidas
Um sistema simples de recomendaÃ§Ã£o baseado nas avaliaÃ§Ãµes
Com isso, o MVP pretende demonstrar como pipelines em nuvem podem apoiar experiÃªncias de recomendaÃ§Ã£o e permitir uma anÃ¡lise eficiente de grandes volumes de dados literÃ¡rios.

# COLETA DE DADOS

# Fonte dos Dados e Processo de Coleta

Os dados utilizados neste projeto foram obtidos de fontes abertas e pÃºblicas, eliminando riscos relacionados Ã  confidencialidade das informaÃ§Ãµes. A base principal reÃºne metadados de livros, avaliaÃ§Ãµes e preferÃªncias de usuÃ¡rios, compondo o insumo necessÃ¡rio para o desenvolvimento de um sistema de recomendaÃ§Ã£o. Foram coletados dados entre os anos de 1998 e 2024, conforme a disponibilidade de cada fonte.

# Tabela Fato â€“ InteraÃ§Ãµes UsuÃ¡rioâ€“Livro

A tabela fato do projeto, denominada fato_interacoes_usuarios_gold, foi construÃ­da a partir de registros de interaÃ§Ãµes (ratings, reviews e marcaÃ§Ãµes) coletados do portal Goodreads por meio de datasets disponibilizados publicamente no Kaggle.

ğŸ”— # Fonte principal:
Goodreads Books Dataset â€“ Kaggle (https://www.kaggle.com/datasets/zygmunt/goodbooks-10k)
(arquivo contendo livros, avaliaÃ§Ãµes, notas e interaÃ§Ãµes de usuÃ¡rios)

Esse dataset foi escolhido por possuir volume significativo, metadata completa e padronizaÃ§Ã£o adequada para anÃ¡lises avanÃ§adas de recomendaÃ§Ã£o.

Os arquivos foram baixados manualmente, no formato CSV, e posteriormente enviados para o repositÃ³rio GitHub do projeto. O pipeline foi configurado para realizar o ingest dos dados diretamente via API do GitHub, permitindo atualizaÃ§Ã£o simplificada e versionada.

Tabelas DimensÃ£o

As tabelas dimensÃ£o foram obtidas de diferentes fontes complementares, conforme detalhado abaixo.

ğŸ“˜ DimensÃ£o Livros (dim_livros_gold)

Para enriquecer as informaÃ§Ãµes dos livros, foi utilizada a base do dataset:

ğŸ”— Fonte:
Goodreads Books Dataset (books.csv)
ContÃ©m: tÃ­tulo, autores, ISBN, idioma, nÃºmero de pÃ¡ginas, ano de publicaÃ§Ã£o, mÃ©dia de avaliaÃ§Ã£o e descriÃ§Ã£o.

Esse conjunto foi selecionado por fornecer metadados essenciais para a qualidade das recomendaÃ§Ãµes baseadas em conteÃºdo (content-based filtering).

ğŸ§‘â€ğŸ’» # DimensÃ£o UsuÃ¡rios (dim_usuarios_gold)

Como as bases pÃºblicas de recomendaÃ§Ã£o nÃ£o incluem dados pessoais, somente IDs anÃ´nimos, utilizamos os identificadores do prÃ³prio dataset:

ğŸ”— Fonte:
Goodreads Interactions Dataset (ratings.csv / interactions.csv)
ContÃ©m: user_id, book_id, rating e timestamp.

Por motivos de privacidade, nenhuma informaÃ§Ã£o sensÃ­vel Ã© incluÃ­da, mantendo o dataset totalmente anonimizado e compatÃ­vel com LGPD.

ğŸ·ï¸ # DimensÃ£o GÃªneros LiterÃ¡rios (dim_generos_gold)

As informaÃ§Ãµes de gÃªneros foram extraÃ­das de forma complementar a partir da API pÃºblica do Google Books, utilizada apenas para enriquecer metadata faltante em alguns livros.

ğŸ”— Fonte:
Google Books API â€“ consulta automatizada para gÃªneros e categorias literÃ¡rias.

Os dados foram coletados em formato JSON e transformados em CSV para carga no pipeline.

ğŸŒ # Outras Tabelas DimensÃ£o Criadas Manualmente

Algumas tabelas possuÃ­am poucas linhas e foram facilmente criadas manualmente em CSV, com separaÃ§Ã£o por â€œ;â€, utilizando um editor de texto. Essas tabelas incluem classificaÃ§Ãµes auxiliares utilizadas no modelo de recomendaÃ§Ã£o:

Popularidade (popularidade_gold)
Faixa de Ano de PublicaÃ§Ã£o (faixa_ano_gold)
Categorias Simplificadas (categoria_simplificada_gold)

Essas tabelas foram construÃ­das com base na estrutura do prÃ³prio dataset e projetadas para auxiliar no enriquecimento do processo analÃ­tico.

# MODELAGEM E CATÃLOGO DE DADOS

Para estruturar e organizar os dados de forma eficiente, foi adotado o Esquema Estrela, amplamente utilizado em soluÃ§Ãµes de Data Warehousing, Business Intelligence e sistemas de recomendaÃ§Ã£o baseados em anÃ¡lises analÃ­ticas.

# Estrutura do Esquema Estrela

O esquema estrela do projeto foi construÃ­do com uma tabela fato principal contendo as interaÃ§Ãµes entre usuÃ¡rios e livros, acompanhada de cinco tabelas dimensÃ£o, que consolidam e organizam os metadados necessÃ¡rios para alimentar o motor de recomendaÃ§Ãµes.

A arquitetura ficou estruturada da seguinte forma:

ğŸ“˜ # Tabela Fato: fato_interacoes_usuarios_gold

A tabela fato contÃ©m os registros de comportamento dos usuÃ¡rios, sendo o nÃºcleo central do modelo.
Cada linha representa uma interaÃ§Ã£o Ãºnica, como:

* avaliaÃ§Ã£o (rating)
* marcaÃ§Ã£o de leitura (read / want-to-read)
* review textual
* data e hora da interaÃ§Ã£o

Esses dados sÃ£o a base para algoritmos de recomendaÃ§Ã£o como:
âœ” Filtragem Colaborativa
âœ” Content-Based Filtering
âœ” Modelos HÃ­bridos

ğŸ“Š # Tabelas DimensÃ£o

Foram criadas tabelas auxiliares para armazenar atributos descritivos, garantindo enriquecimento e consistÃªncia das anÃ¡lises por meio de joins.

As dimensÃµes utilizadas foram:

* dim_livros_gold â€“ informaÃ§Ãµes dos livros (tÃ­tulo, autor, ISBN, idioma, ano)
* dim_usuarios_gold â€“ identificador do usuÃ¡rio (anonimizado)
* dim_generos_gold â€“ gÃªneros literÃ¡rios e categorias temÃ¡ticas
* dim_popularidade_gold â€“ classificaÃ§Ã£o de popularidade baseada em mÃ©dia de notas e volume de reviews
* dim_ano_publicacao_gold â€“ agrupamentos de ano para anÃ¡lises temporais

Essas dimensÃµes permitem que cada interaÃ§Ã£o seja contextualizada, criando um ambiente analÃ­tico robusto para recomendaÃ§Ãµes personalizadas.

# CatÃ¡logo de Dados
ğŸ“Œ # Tabela fato_interacoes_usuarios_gold

A tabela fato foi construÃ­da a partir da base original do Goodreads, que continha dezenas de campos sobre avaliaÃ§Ãµes, metadados do livro e comportamento do usuÃ¡rio.

Durante o processo de ETL, vÃ¡rios campos redundantes ou irrelevantes foram removidos, resultando em uma estrutura mais enxuta, organizada e otimizada para anÃ¡lises de recomendaÃ§Ã£o.

A estrutura final da tabela fato contÃ©m os seguintes campos:
ğŸ“Œ Tabelas DimensÃ£o

| Campo            | DescriÃ§Ã£o                                    |
| ---------------- | -------------------------------------------- |
| interaction_id   | Identificador Ãºnico da interaÃ§Ã£o             |
| user_id          | Identificador anonimizado do usuÃ¡rio         |
| book_id          | Identificador Ãºnico do livro                 |
| rating           | Nota atribuÃ­da pelo usuÃ¡rio                  |
| review_text      | Texto do comentÃ¡rio (quando disponÃ­vel)      |
| interaction_type | Tipo de interaÃ§Ã£o (rating, review, marcaÃ§Ã£o) |
| timestamp        | Data/hora da interaÃ§Ã£o                       |
| source           | Origem do dado (Goodreads / Kaggle / API)    |

Resumo da estrutura das dimensÃµes incluÃ­das no modelo:
# dim_livros_gold

| Campo            | DescriÃ§Ã£o                 |
| ---------------- | ------------------------- |
| book_id          | Chave primÃ¡ria do livro   |
| title            | TÃ­tulo                    |
| authors          | Autor(es)                 |
| isbn             | IdentificaÃ§Ã£o ISBN        |
| language         | Idioma                    |
| pages            | NÃºmero de pÃ¡ginas         |
| publication_year | Ano de publicaÃ§Ã£o         |
| avg_rating       | MÃ©dia geral de avaliaÃ§Ãµes |

# dim_usuarios_gold

| Campo         | DescriÃ§Ã£o                  |
| ------------- | -------------------------- |
| user_id       | Identificador anonimizado  |
| total_reviews | Volume de reviews escritos |
| total_ratings | Total de avaliaÃ§Ãµes        |

# dim_generos_gold
| Campo      | DescriÃ§Ã£o                |
| ---------- | ------------------------ |
| genre_id   | Chave primÃ¡ria           |
| genre_name | Nome do gÃªnero literÃ¡rio |

# dim_popularidade_gold
| Campo            | DescriÃ§Ã£o                        |
| ---------------- | -------------------------------- |
| popularity_id    | Chave primÃ¡ria                   |
| popularity_level | Baixa / MÃ©dia / Alta             |
| rule             | Regra utilizada na classificaÃ§Ã£o |

# dim_ano_publicacao_gold
| Campo       | DescriÃ§Ã£o                       |
| ----------- | ------------------------------- |
| year_group  | Faixa de ano (ex.: "1990â€“1999") |
| description | Categoria analÃ­tica             |

![image alt](https://github.com/claudianaandradec/MVP-Engenharia-de-dados/blob/a3d93143e37b0f6e5e48777a1158f837517be1c7/Diagrama%20ER.jpg)

Carga (ETL) â€“ Pipeline no Databricks

Nesta etapa serÃ¡ construÃ­do o pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) responsÃ¡vel por ingerir, limpar, padronizar e disponibilizar os dados no Delta Lake.

Utilizaremos a arquitetura Medallion, dividindo o processamento em trÃªs camadas:

ğŸ¥‰ Bronze â€“ dados brutos

ğŸ¥ˆ Silver â€“ dados tratados e padronizados

ğŸ¥‡ Gold â€“ dados modelados no Esquema Estrela

[carga] esta sessÃ£o esta no notebook

ANÃLISE DE QUALIDADE DOS DADOS
Durante a execuÃ§Ã£o do pipeline de dados (arquitetura Medallion: Bronze â†’ Silver â†’ Gold), os dados passaram por diversas verificaÃ§Ãµes de integridade, tipagem e consistÃªncia. O objetivo foi garantir que a camada final (Gold) estivesse apta para gerar insights confiÃ¡veis sobre o comportamento de leitura.
Nesta seÃ§Ã£o, foi detalahda a qualidade dos atributos, os problemas encontrados nos arquivos brutos e as soluÃ§Ãµes tÃ©cnicas aplicadas.
1. SeleÃ§Ã£o e Limpeza de Atributos
O dataset original (books.csv) possuÃ­a diversas colunas irrelevantes para o objetivo analÃ­tico deste MVP, como URLs de capas de livros (image_url, small_image_url) e mÃºltiplos contadores internos redundantes.
Para otimizar o armazenamento e a performance das consultas no Data Warehouse, foi realizada a remoÃ§Ã£o dessas colunas durante a transiÃ§Ã£o para a camada Silver, mantendo apenas os metadados essenciais (tÃ­tulo, autor, ano, ISBN e identificadores).
2. InconsistÃªncias de Tipagem e "Dados Sujos"
Um dos problemas crÃ­ticos identificados foi a presenÃ§a de "sujeira" (dirty data) em colunas numÃ©ricas.
Problema: Na coluna average_rating, que deveria conter apenas valores decimais (double), foram encontrados registros contendo texto (ex: o valor "eng", que pertence Ã  coluna de idioma, foi deslocado para a coluna de nota em algumas linhas corrompidas).
SoluÃ§Ã£o: foi utilizada a funÃ§Ã£o try_cast do Spark. Diferente de uma conversÃ£o comum que falharia o pipeline, essa abordagem converteu os valores invÃ¡lidos para NULL. Em seguida, aplicamos um filtro (isNotNull) na chave primÃ¡ria para descartar essas linhas corrompidas, garantindo que apenas livros com dados estruturados chegassem Ã  camada Gold.
3. Tratamento de Identificadores (Chaves PrimÃ¡rias)
Houve uma inconsistÃªncia semÃ¢ntica nos identificadores dos livros. O dataset continha dois IDs distintos: um sequencial do prÃ³prio arquivo (book_id) e outro original do site Goodreads (goodreads_book_id).
Problema: A tabela de tags utilizava o ID do site, enquanto a tabela de ratings utilizava o ID sequencial.
SoluÃ§Ã£o: Realizado um mapeamento explÃ­cito e renomeaÃ§Ã£o dessas colunas na camada Silver. Isso garantiu a integridade referencial nos Joins da camada Gold, permitindo cruzar corretamente as avaliaÃ§Ãµes dos usuÃ¡rios com os gÃªneros literÃ¡rios.
4. Tratamento de Valores Nulos e Duplicatas
Duplicatas: Embora raro, o processo de ingestÃ£o poderia gerar duplicidade de processamento. Foi aplicada a funÃ§Ã£o .dropDuplicates() baseada nas chaves naturais (ex: um usuÃ¡rio nÃ£o pode ter duas avaliaÃ§Ãµes para o mesmo livro; mantivemos apenas a mais recente ou Ãºnica).
Nulos: Campos textuais essenciais, como original_title, passaram por tratamento de limpeza (trim) para remover espaÃ§os em branco. Para livros sem histÃ³rico de avaliaÃ§Ãµes no dataset, foi preenchido os valores nulos de contagem com 0 (zero) para nÃ£o prejudicar os cÃ¡lculos de mÃ©dia.
5. Qualidade EstatÃ­stica para RecomendaÃ§Ã£o
Notou-se que alguns livros possuÃ­am mÃ©dias de avaliaÃ§Ã£o muito altas (5.0), mas com apenas 1 ou 2 votos. Estatisticamente, isso gera um viÃ©s de recomendaÃ§Ã£o ("falsos melhores livros").
SoluÃ§Ã£o: Foram criadas regras de negÃ³cio na camada Gold para classificar a popularidade. Nas anÃ¡lises de recomendaÃ§Ã£o, foram aplicados filtros (ex: ratings_count > 100) para garantir que os insights refletissem o consenso da comunidade e nÃ£o outliers.
ConclusÃ£o
ApÃ³s as etapas de limpeza, tipagem robusta (uso de try_cast) e modelagem dimensional, os dados atingiram um nÃ­vel de qualidade satisfatÃ³rio. As inconsistÃªncias estruturais foram sanadas na camada Silver, permitindo que a camada Gold responda Ã s perguntas de negÃ³cio com precisÃ£o e sem interrupÃ§Ãµes no processamento.
